{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6f3ee1-b9e7-4a74-bf37-0a802565018f",
   "metadata": {},
   "source": [
    "## Import libraries and warnings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d73bbde-3e35-445d-b11c-64a45e3ced76",
   "metadata": {},
   "source": [
    "# Run this in a new cell in your Jupyter Notebook\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d28558-a980-4a81-8550-eaedc00c7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FutureWarnings are now ignored.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore # For calculating Z-scores\n",
    "\n",
    "\n",
    "# Option 1: Ignore all FutureWarnings globally\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print(\"FutureWarnings are now ignored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17038e-a695-4854-a5c8-6f55c580a5e9",
   "metadata": {},
   "source": [
    "## Load and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4741215f-e335-4e3a-978c-c5e9021fb24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EnumID</th>\n",
       "      <th>State</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Family Setting</th>\n",
       "      <th>Num of Children</th>\n",
       "      <th>Educational Status</th>\n",
       "      <th>Employment Status</th>\n",
       "      <th>Monthly Income</th>\n",
       "      <th>...</th>\n",
       "      <th>Meds_Explained_SideFX</th>\n",
       "      <th>Encourage_Questions</th>\n",
       "      <th>Respond_Q_Concerns</th>\n",
       "      <th>Showed_Personal_Concern</th>\n",
       "      <th>Involved_In_Decisions</th>\n",
       "      <th>Discuss_NextSteps</th>\n",
       "      <th>Checked_Understanding</th>\n",
       "      <th>Time_Spent_Adequate</th>\n",
       "      <th>Visit_Satisfaction</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYNTH-NEU-284</td>\n",
       "      <td>Jigawa</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>1-2</td>\n",
       "      <td>Tertiary education (e.g., University, college)</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Less than 20,000 Naira</td>\n",
       "      <td>...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Neither Agree or Disagree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC023</td>\n",
       "      <td>Bauchi</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Polygamy</td>\n",
       "      <td>Greater than 4</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Less than 20,000 Naira</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Very satisfied</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SYNTH-SAT-140</td>\n",
       "      <td>Jigawa</td>\n",
       "      <td>55 years and above</td>\n",
       "      <td>Female</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>1-2</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>51,000–100,000 Naira</td>\n",
       "      <td>...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Satisfied</td>\n",
       "      <td>Synthetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JG14</td>\n",
       "      <td>Jigawa</td>\n",
       "      <td>35–44</td>\n",
       "      <td>Female</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>1-2</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Employed part-time</td>\n",
       "      <td>Less than 20,000 Naira</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Very satisfied</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SYNTH-VER-519</td>\n",
       "      <td>Bauchi</td>\n",
       "      <td>35–44</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>Greater than 4</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Less than 20,000 Naira</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Strongly Agree</td>\n",
       "      <td>Very dissatisfied</td>\n",
       "      <td>Synthetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          EnumID   State                 Age  Gender Marital Status  \\\n",
       "0  SYNTH-NEU-284  Jigawa               25-34  Female        Married   \n",
       "1          BC023  Bauchi               25-34  Female        Widowed   \n",
       "2  SYNTH-SAT-140  Jigawa  55 years and above  Female        Widowed   \n",
       "3           JG14  Jigawa               35–44  Female       Divorced   \n",
       "4  SYNTH-VER-519  Bauchi               35–44  Female         Single   \n",
       "\n",
       "  Family Setting Num of Children  \\\n",
       "0       Monogamy             1-2   \n",
       "1       Polygamy  Greater than 4   \n",
       "2       Monogamy             1-2   \n",
       "3       Monogamy             1-2   \n",
       "4       Monogamy  Greater than 4   \n",
       "\n",
       "                               Educational Status   Employment Status  \\\n",
       "0  Tertiary education (e.g., University, college)       Self-employed   \n",
       "1                             No formal education       Self-employed   \n",
       "2                             Secondary education          Unemployed   \n",
       "3                             Secondary education  Employed part-time   \n",
       "4                             Secondary education       Self-employed   \n",
       "\n",
       "           Monthly Income  ... Meds_Explained_SideFX Encourage_Questions  \\\n",
       "0  Less than 20,000 Naira  ...                 Agree               Agree   \n",
       "1  Less than 20,000 Naira  ...        Strongly Agree      Strongly Agree   \n",
       "2    51,000–100,000 Naira  ...                 Agree               Agree   \n",
       "3  Less than 20,000 Naira  ...        Strongly Agree      Strongly Agree   \n",
       "4  Less than 20,000 Naira  ...        Strongly Agree      Strongly Agree   \n",
       "\n",
       "          Respond_Q_Concerns Showed_Personal_Concern Involved_In_Decisions  \\\n",
       "0  Neither Agree or Disagree          Strongly Agree                 Agree   \n",
       "1                      Agree                Disagree                 Agree   \n",
       "2                      Agree                   Agree                 Agree   \n",
       "3             Strongly Agree          Strongly Agree        Strongly Agree   \n",
       "4             Strongly Agree          Strongly Agree                 Agree   \n",
       "\n",
       "  Discuss_NextSteps Checked_Understanding Time_Spent_Adequate  \\\n",
       "0             Agree                 Agree               Agree   \n",
       "1             Agree              Disagree               Agree   \n",
       "2             Agree                 Agree            Disagree   \n",
       "3    Strongly Agree        Strongly Agree      Strongly Agree   \n",
       "4    Strongly Agree        Strongly Agree      Strongly Agree   \n",
       "\n",
       "  Visit_Satisfaction     Source  \n",
       "0            Neutral  Synthetic  \n",
       "1     Very satisfied   Original  \n",
       "2          Satisfied  Synthetic  \n",
       "3     Very satisfied   Original  \n",
       "4  Very dissatisfied  Synthetic  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/balanced_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbb59ce-0ca7-4980-afef-e9e3446c0292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1046 entries, 0 to 1045\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   EnumID                    1046 non-null   object\n",
      " 1   State                     1046 non-null   object\n",
      " 2   Age                       1046 non-null   object\n",
      " 3   Gender                    1046 non-null   object\n",
      " 4   Marital Status            1046 non-null   object\n",
      " 5   Family Setting            1046 non-null   object\n",
      " 6   Num of Children           1046 non-null   object\n",
      " 7   Educational Status        1046 non-null   object\n",
      " 8   Employment Status         1046 non-null   object\n",
      " 9   Monthly Income            1046 non-null   object\n",
      " 10  Treatment Regimen         1046 non-null   object\n",
      " 11  HIV_Duration_Years        1046 non-null   object\n",
      " 12  Care_Duration_Years       1046 non-null   object\n",
      " 13  Facility_Care_Dur_Years   1046 non-null   object\n",
      " 14  HIV_Diag_Type             1046 non-null   object\n",
      " 15  Greet_Comfort             1046 non-null   object\n",
      " 16  Discuss_VisitReason       1046 non-null   object\n",
      " 17  Encourage_Thoughts        1046 non-null   object\n",
      " 18  Listen_Careful            1046 non-null   object\n",
      " 19  Understood_You            1046 non-null   object\n",
      " 20  Exam_Explained            1046 non-null   object\n",
      " 21  LabTests_Explained        1046 non-null   object\n",
      " 22  Discuss_TreatOptions      1046 non-null   object\n",
      " 23  Info_AsDesired            1046 non-null   object\n",
      " 24  Plan_Acceptability_Check  1046 non-null   object\n",
      " 25  Meds_Explained_SideFX     1046 non-null   object\n",
      " 26  Encourage_Questions       1046 non-null   object\n",
      " 27  Respond_Q_Concerns        1046 non-null   object\n",
      " 28  Showed_Personal_Concern   1046 non-null   object\n",
      " 29  Involved_In_Decisions     1046 non-null   object\n",
      " 30  Discuss_NextSteps         1046 non-null   object\n",
      " 31  Checked_Understanding     1046 non-null   object\n",
      " 32  Time_Spent_Adequate       1046 non-null   object\n",
      " 33  Visit_Satisfaction        1046 non-null   object\n",
      " 34  Source                    1046 non-null   object\n",
      "dtypes: object(35)\n",
      "memory usage: 286.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8233c6-3e00-4ae4-82da-bd2cee2b5a42",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b17f4c-5007-4742-9856-c2c8de4e6435",
   "metadata": {},
   "source": [
    "### Combine Target Labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baa0746e-485a-46fb-9b0a-616cb5081123",
   "metadata": {},
   "source": [
    "# Combine 'Neutral' and 'Very dissatisfied' into 'Not satisfied'\n",
    "df['Visit_Satisfaction'] = df['Visit_Satisfaction'].replace(\n",
    "    ['Neutral', 'Very dissatisfied'],\n",
    "    'Not satisfied'\n",
    ")\n",
    "\n",
    "df['Visit_Satisfaction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1ca82-ce49-47e7-b956-7eac2f0b6ce6",
   "metadata": {},
   "source": [
    "### Transformation of Continuous Variables (Currently Categorical Ranges)\n",
    "\n",
    "#### 1. Transform 'Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca266b6-def7-4788-a491-803ac21d40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformed 'Age' ---\n",
      "[29.5 65.  39.5 21.  49.5]\n"
     ]
    }
   ],
   "source": [
    "#@title 1. Transform 'Age'\n",
    "age_mapping = {\n",
    "    '18–24': 21,\n",
    "    '25-34': 29.5,\n",
    "    '35–44': 39.5,\n",
    "    '45–54': 49.5,\n",
    "    '55 years and above': 65 # Estimating 65 as a reasonable midpoint for an open-ended \"above 55\"\n",
    "}\n",
    "df['Age'] = df['Age'].replace(age_mapping).astype(float) # Convert to float\n",
    "\n",
    "print(\"--- Transformed 'Age' ---\")\n",
    "print(df['Age'].unique())\n",
    "#print(df[['Age']].head())\n",
    "#print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85636b-0ec5-4703-8a35-c164e7a577f5",
   "metadata": {},
   "source": [
    "#### 2. Transform 'Num of Children'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfedeb3a-9768-48a2-98b0-b479ffde57ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformed 'Num of Children' ---\n",
      "[1.5 5.  3.5]\n"
     ]
    }
   ],
   "source": [
    "#@title 2. Transform 'Num of Children'\n",
    "\n",
    "children_mapping = {\n",
    "    '1-2': 1.5,\n",
    "    '3-4': 3.5,\n",
    "    'Greater than 4': 5 # Estimating 5 as a reasonable value for \"Greater than 4\"\n",
    "}\n",
    "df['Num of Children'] = df['Num of Children'].replace(children_mapping).astype(float)\n",
    "\n",
    "print(\"--- Transformed 'Num of Children' ---\")\n",
    "print(df['Num of Children'].unique())\n",
    "#print(df[['Num of Children']].head())\n",
    "#print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398781ac-a30c-42c8-b307-0c5e51b97a1a",
   "metadata": {},
   "source": [
    "#### 3. Transform 'Monthly Income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ceec46-cbb6-48f5-9605-533b861544e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformed 'Monthly Income' ---\n",
      "[ 10000.  75500.  35000.     nan 150500. 250000.]\n"
     ]
    }
   ],
   "source": [
    "#@title 3. Transform 'Monthly Income'\n",
    "income_mapping = {\n",
    "    'Less than 20,000 Naira': 10000,\n",
    "    '20,000–50,000 Naira': 35000,\n",
    "    '51,000–100,000 Naira': 75500,\n",
    "    '101,000–200,000 Naira': 150500,\n",
    "    'More than 200,000 Naira': 250000, # Estimating 250,000 as a reasonable value\n",
    "    'Prefer not to say': np.nan # Map 'Prefer not to say' to NaN\n",
    "}\n",
    "df['Monthly Income'] = df['Monthly Income'].replace(income_mapping).astype(float)\n",
    "\n",
    "print(\"--- Transformed 'Monthly Income' ---\")\n",
    "print(df['Monthly Income'].unique())\n",
    "#print(df[['Monthly Income']].head())\n",
    "#print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf6fff-aca6-411a-855a-9ef831b0e4a2",
   "metadata": {},
   "source": [
    "#### 4. Transform Duration Columns (HIV_Duration_Years, Care_Duration_Years, Facility_Care_Dur_Years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432ee768-9883-4aef-8127-87a55fc5490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transformed 'HIV_Duration_Years' ---\n",
      "[ 2.  12.5  9.   0.5  5.5]\n",
      "--- Transformed 'Care_Duration_Years' ---\n",
      "[12.5  0.5  2.   9.   5.5]\n",
      "--- Transformed 'Facility_Care_Dur_Years' ---\n",
      "[ 2.   0.5  9.  12.5  5.5]\n"
     ]
    }
   ],
   "source": [
    "#@title 4. Transform Duration Columns (HIV_Duration_Years, Care_Duration_Years, Facility_Care_Dur_Years)\n",
    "# Note: Pay attention to different hyphens (en-dash vs. hyphen)\n",
    "duration_mapping = {\n",
    "    'Less than 1 year': 0.5,\n",
    "    '1-3 years': 2,\n",
    "    '1–3 years': 2, # Handle en-dash variation\n",
    "    '4-7 years': 5.5,\n",
    "    '4–7 years': 5.5, # Handle en-dash variation\n",
    "    '8-10 years': 9,\n",
    "    '8–10 years': 9, # Handle en-dash variation\n",
    "    'More than 10 years': 12.5 # Estimating 12.5 as a reasonable value\n",
    "}\n",
    "\n",
    "for col in ['HIV_Duration_Years', 'Care_Duration_Years', 'Facility_Care_Dur_Years']:\n",
    "    df[col] = df[col].replace(duration_mapping).astype(float)\n",
    "    print(f\"--- Transformed '{col}' ---\")\n",
    "    print(df[col].unique())\n",
    "    #print(df[[col]].head())\n",
    "    #print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68de54-3c35-4da7-836c-6fd1f6bd57b7",
   "metadata": {},
   "source": [
    "#### Fill the missing data points in Monthly Income with Imputation with a Missing Indicator (using Median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c7f6b1-46a1-4234-8e70-bd121a905cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Income after imputation and adding missing indicator:\n",
      "    Monthly Income  Monthly_Income_Missing\n",
      "38         35000.0                       1\n",
      "\n",
      "Value counts for Monthly_Income_Missing:\n",
      "Monthly_Income_Missing\n",
      "0    893\n",
      "1    153\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Monthly_Income:\n",
      "Monthly Income\n",
      "10000.0     432\n",
      "35000.0     334\n",
      "75500.0     205\n",
      "150500.0     66\n",
      "250000.0      9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#@title Fill the missing data points in Monthly Income with Imputation with a Missing Indicator (using Median)\n",
    "# Create the missing indicator column\n",
    "df['Monthly_Income_Missing'] = df['Monthly Income'].isna().astype(int)\n",
    "\n",
    "# Then, fill the NaNs in the original column using median imputation\n",
    "median_income = df['Monthly Income'].median()\n",
    "df['Monthly Income'].fillna(median_income, inplace=True)\n",
    "\n",
    "print(\"Monthly Income after imputation and adding missing indicator:\")\n",
    "print(df[['Monthly Income', 'Monthly_Income_Missing']].sample())\n",
    "print(\"\\nValue counts for Monthly_Income_Missing:\")\n",
    "print(df['Monthly_Income_Missing'].value_counts())\n",
    "print(\"\\nValue counts for Monthly_Income:\")\n",
    "print(df['Monthly Income'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f89e84-50ba-4ed2-b43d-f887d38b9dde",
   "metadata": {},
   "source": [
    "### Identify outlier with Z-score and treat the identified outlier with Log Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3b01e-f72d-4ef1-80b1-74eb6d6ba9c3",
   "metadata": {},
   "source": [
    "#### A. Identify outlier with Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e29fc2-278e-4f0d-8374-870176e7b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Outlier Identification (Z-score) ---\n",
      "Column: 'Age'\n",
      "  No potential outliers found with |Z-score| > 3 for 'Age'.\n",
      "--------------------------------------------------------------------------------\n",
      "Column: 'Num of Children'\n",
      "  No potential outliers found with |Z-score| > 3 for 'Num of Children'.\n",
      "--------------------------------------------------------------------------------\n",
      "Column: 'Monthly Income'\n",
      "  9 potential outlier(s) with |Z-score| > 3:\n",
      "     Monthly Income  Monthly Income_zscore\n",
      "77         250000.0               4.945044\n",
      "112        250000.0               4.945044\n",
      "253        250000.0               4.945044\n",
      "305        250000.0               4.945044\n",
      "396        250000.0               4.945044\n",
      "554        250000.0               4.945044\n",
      "730        250000.0               4.945044\n",
      "909        250000.0               4.945044\n",
      "968        250000.0               4.945044\n",
      "--------------------------------------------------------------------------------\n",
      "Column: 'HIV_Duration_Years'\n",
      "  No potential outliers found with |Z-score| > 3 for 'HIV_Duration_Years'.\n",
      "--------------------------------------------------------------------------------\n",
      "Column: 'Care_Duration_Years'\n",
      "  No potential outliers found with |Z-score| > 3 for 'Care_Duration_Years'.\n",
      "--------------------------------------------------------------------------------\n",
      "Column: 'Facility_Care_Dur_Years'\n",
      "  No potential outliers found with |Z-score| > 3 for 'Facility_Care_Dur_Years'.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Columns identified for log transformation (with outliers): ['Monthly Income']\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Identify outlier with Z-score\n",
    "\n",
    "# List of continuous numerical columns to process\n",
    "continuous_cols = [\n",
    "    'Age',\n",
    "    'Num of Children',\n",
    "    'Monthly Income',\n",
    "    'HIV_Duration_Years',\n",
    "    'Care_Duration_Years',\n",
    "    'Facility_Care_Dur_Years'\n",
    "]\n",
    "\n",
    "# --- Outlier Identification using Z-score ---\n",
    "# This loop both IDENTIFIES and POPULATES the list of outlier columns.\n",
    "# It MUST be run before the log transformation loop.\n",
    "cols_with_outliers_for_transform = []\n",
    "print(\"--- Outlier Identification (Z-score) ---\")\n",
    "for col in continuous_cols:\n",
    "    df[f'{col}_zscore'] = np.abs(zscore(df[col]))\n",
    "    outliers = df[df[f'{col}_zscore'] > 3]\n",
    "    print(f\"Column: '{col}'\")\n",
    "    if not outliers.empty:\n",
    "        print(f\"  {len(outliers)} potential outlier(s) with |Z-score| > 3:\")\n",
    "        print(outliers[[col, f'{col}_zscore']])\n",
    "        cols_with_outliers_for_transform.append(col)\n",
    "    else:\n",
    "        print(f\"  No potential outliers found with |Z-score| > 3 for '{col}'.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nColumns identified for log transformation (with outliers): {cols_with_outliers_for_transform}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e3a324-5839-4cce-9c35-0c9d5a7a430d",
   "metadata": {},
   "source": [
    "#### B. Treat the identified outlier with Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e60d3b3-eeec-4e96-b01b-6b72ca8b43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Applying Log Transformation (np.log1p) to identified outlier columns ---\n",
      "'Age' not transformed (no significant outliers detected).\n",
      "'Num of Children' not transformed (no significant outliers detected).\n",
      "'Monthly Income' transformed to 'Monthly Income_log' (due to outliers).\n",
      "'HIV_Duration_Years' not transformed (no significant outliers detected).\n",
      "'Care_Duration_Years' not transformed (no significant outliers detected).\n",
      "'Facility_Care_Dur_Years' not transformed (no significant outliers detected).\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Outlier Treatment with Log Transformation (Conditional) ---\n",
    "# This loop depends on the list created above.\n",
    "print(\"--- Applying Log Transformation (np.log1p) to identified outlier columns ---\")\n",
    "transformed_cols_display = []\n",
    "for col in continuous_cols:\n",
    "    if col in cols_with_outliers_for_transform: # The variable must be defined by now\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "        print(f\"'{col}' transformed to '{col}_log' (due to outliers).\")\n",
    "        transformed_cols_display.append(col)\n",
    "    else:\n",
    "        print(f\"'{col}' not transformed (no significant outliers detected).\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c1bbe1-6a0d-44f2-bd98-bf9eb27fe605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final DataFrame head with original, Z-score, and conditionally log-transformed columns ---\n",
      "    Age  Age_zscore  Num of Children  Num of Children_zscore  Monthly Income  \\\n",
      "0  29.5    0.871247              1.5                1.445493         10000.0   \n",
      "1  29.5    0.871247              5.0                0.992070         10000.0   \n",
      "2  65.0    2.224935              1.5                1.445493         75500.0   \n",
      "3  39.5    0.000917              1.5                1.445493         10000.0   \n",
      "4  39.5    0.000917              5.0                0.992070         10000.0   \n",
      "\n",
      "   Monthly Income_zscore  Monthly Income_log  HIV_Duration_Years  \\\n",
      "0               0.753926            9.210440                 2.0   \n",
      "1               0.753926            9.210440                12.5   \n",
      "2               0.801418           11.231901                 2.0   \n",
      "3               0.753926            9.210440                12.5   \n",
      "4               0.753926            9.210440                 9.0   \n",
      "\n",
      "   HIV_Duration_Years_zscore  Care_Duration_Years  Care_Duration_Years_zscore  \\\n",
      "0                   1.500846                 12.5                    0.990137   \n",
      "1                   0.968636                  0.5                    1.803030   \n",
      "2                   1.500846                  2.0                    1.453884   \n",
      "3                   0.968636                 12.5                    0.990137   \n",
      "4                   0.145475                  9.0                    0.175463   \n",
      "\n",
      "   Facility_Care_Dur_Years  Facility_Care_Dur_Years_zscore  \n",
      "0                      2.0                        1.191044  \n",
      "1                      0.5                        1.554119  \n",
      "2                      9.0                        0.503307  \n",
      "3                     12.5                        1.350482  \n",
      "4                      9.0                        0.503307  \n",
      "\n",
      "DataFrame Info (check dtypes and new columns):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1046 entries, 0 to 1045\n",
      "Data columns (total 43 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   EnumID                          1046 non-null   object \n",
      " 1   State                           1046 non-null   object \n",
      " 2   Age                             1046 non-null   float64\n",
      " 3   Gender                          1046 non-null   object \n",
      " 4   Marital Status                  1046 non-null   object \n",
      " 5   Family Setting                  1046 non-null   object \n",
      " 6   Num of Children                 1046 non-null   float64\n",
      " 7   Educational Status              1046 non-null   object \n",
      " 8   Employment Status               1046 non-null   object \n",
      " 9   Monthly Income                  1046 non-null   float64\n",
      " 10  Treatment Regimen               1046 non-null   object \n",
      " 11  HIV_Duration_Years              1046 non-null   float64\n",
      " 12  Care_Duration_Years             1046 non-null   float64\n",
      " 13  Facility_Care_Dur_Years         1046 non-null   float64\n",
      " 14  HIV_Diag_Type                   1046 non-null   object \n",
      " 15  Greet_Comfort                   1046 non-null   object \n",
      " 16  Discuss_VisitReason             1046 non-null   object \n",
      " 17  Encourage_Thoughts              1046 non-null   object \n",
      " 18  Listen_Careful                  1046 non-null   object \n",
      " 19  Understood_You                  1046 non-null   object \n",
      " 20  Exam_Explained                  1046 non-null   object \n",
      " 21  LabTests_Explained              1046 non-null   object \n",
      " 22  Discuss_TreatOptions            1046 non-null   object \n",
      " 23  Info_AsDesired                  1046 non-null   object \n",
      " 24  Plan_Acceptability_Check        1046 non-null   object \n",
      " 25  Meds_Explained_SideFX           1046 non-null   object \n",
      " 26  Encourage_Questions             1046 non-null   object \n",
      " 27  Respond_Q_Concerns              1046 non-null   object \n",
      " 28  Showed_Personal_Concern         1046 non-null   object \n",
      " 29  Involved_In_Decisions           1046 non-null   object \n",
      " 30  Discuss_NextSteps               1046 non-null   object \n",
      " 31  Checked_Understanding           1046 non-null   object \n",
      " 32  Time_Spent_Adequate             1046 non-null   object \n",
      " 33  Visit_Satisfaction              1046 non-null   object \n",
      " 34  Source                          1046 non-null   object \n",
      " 35  Monthly_Income_Missing          1046 non-null   int64  \n",
      " 36  Age_zscore                      1046 non-null   float64\n",
      " 37  Num of Children_zscore          1046 non-null   float64\n",
      " 38  Monthly Income_zscore           1046 non-null   float64\n",
      " 39  HIV_Duration_Years_zscore       1046 non-null   float64\n",
      " 40  Care_Duration_Years_zscore      1046 non-null   float64\n",
      " 41  Facility_Care_Dur_Years_zscore  1046 non-null   float64\n",
      " 42  Monthly Income_log              1046 non-null   float64\n",
      "dtypes: float64(13), int64(1), object(29)\n",
      "memory usage: 351.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Final display\n",
    "display_cols_final = []\n",
    "for col in continuous_cols:\n",
    "    display_cols_final.append(col)\n",
    "    display_cols_final.append(f'{col}_zscore')\n",
    "    if col in transformed_cols_display:\n",
    "        display_cols_final.append(f'{col}_log')\n",
    "\n",
    "print(\"\\n--- Final DataFrame head with original, Z-score, and conditionally log-transformed columns ---\")\n",
    "print(df[display_cols_final].head())\n",
    "\n",
    "print(\"\\nDataFrame Info (check dtypes and new columns):\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2fb1a-b628-4957-8cfb-c17655351fad",
   "metadata": {},
   "source": [
    "### Define Likert columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4aa597-e081-44e4-adb7-b712f236f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greet_Comfort: ['Strongly Disagree' 'Agree' 'Strongly Agree' 'Disagree'\n",
      " 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Discuss_VisitReason: ['Agree' 'Strongly Agree' 'Strongly Disagree' 'Disagree'\n",
      " 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Encourage_Thoughts: ['Strongly Agree' 'Agree' 'Neither Agree Or Disagree' 'Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Listen_Careful: ['Agree' 'Strongly Agree' 'Disagree' 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Understood_You: ['Strongly Agree' 'Agree' 'Neither Agree Or Disagree' 'Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Exam_Explained: ['Agree' 'Strongly Agree' 'Disagree' 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "LabTests_Explained: ['Agree' 'Strongly Agree' 'Disagree' 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Discuss_TreatOptions: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree' 'Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Info_AsDesired: ['Strongly Agree' 'Agree' 'Neither Agree Or Disagree' 'Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Plan_Acceptability_Check: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree' 'Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Meds_Explained_SideFX: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree' 'Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Encourage_Questions: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree' 'Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Respond_Q_Concerns: ['Neither Agree Or Disagree' 'Agree' 'Strongly Agree' 'Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Showed_Personal_Concern: ['Strongly Agree' 'Disagree' 'Agree' 'Neither Agree Or Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Involved_In_Decisions: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree' 'Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Discuss_NextSteps: ['Agree' 'Strongly Agree' 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Checked_Understanding: ['Agree' 'Disagree' 'Strongly Agree' 'Neither Agree Or Disagree'\n",
      " 'Strongly Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Time_Spent_Adequate: ['Agree' 'Disagree' 'Strongly Agree' 'Neither Agree Or Disagree']\n",
      "--------------------------------------------------------------------------------\n",
      "Visit_Satisfaction: ['Neutral' 'Very Satisfied' 'Satisfied' 'Very Dissatisfied']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define Likert columns (can adjust if needed)\n",
    "likert_columns = [\n",
    "       'Greet_Comfort', 'Discuss_VisitReason', 'Encourage_Thoughts',\n",
    "       'Listen_Careful', 'Understood_You', 'Exam_Explained',\n",
    "       'LabTests_Explained', 'Discuss_TreatOptions', 'Info_AsDesired',\n",
    "       'Plan_Acceptability_Check', 'Meds_Explained_SideFX',\n",
    "       'Encourage_Questions', 'Respond_Q_Concerns', 'Showed_Personal_Concern',\n",
    "       'Involved_In_Decisions', 'Discuss_NextSteps', 'Checked_Understanding',\n",
    "       'Time_Spent_Adequate', 'Visit_Satisfaction'\n",
    "]\n",
    "\n",
    "# Strip whitespace and standardize casing\n",
    "for col in likert_columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# Check unique values post-cleanup with dotted lines\n",
    "for col in likert_columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "    print(\"-\" * 80) # Prints a dotted line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa013851-b24f-46d8-a0eb-ff6b156169a1",
   "metadata": {},
   "source": [
    "### Check for Misspellings and Unexpected Categories\n",
    "\n",
    "#### Quick Frequency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58465f82-dec8-4e03-bd0f-6cc1347498cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Greet_Comfort value counts:\n",
      "Greet_Comfort\n",
      "Strongly Agree               532\n",
      "Agree                        440\n",
      "Strongly Disagree             53\n",
      "Disagree                      13\n",
      "Neither Agree Or Disagree      8\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Discuss_VisitReason value counts:\n",
      "Discuss_VisitReason\n",
      "Agree                        496\n",
      "Strongly Agree               473\n",
      "Strongly Disagree             28\n",
      "Neither Agree Or Disagree     27\n",
      "Disagree                      22\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Encourage_Thoughts value counts:\n",
      "Encourage_Thoughts\n",
      "Strongly Agree               560\n",
      "Agree                        421\n",
      "Neither Agree Or Disagree     51\n",
      "Disagree                      14\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Listen_Careful value counts:\n",
      "Listen_Careful\n",
      "Agree                        553\n",
      "Strongly Agree               452\n",
      "Neither Agree Or Disagree     24\n",
      "Disagree                      17\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Understood_You value counts:\n",
      "Understood_You\n",
      "Strongly Agree               459\n",
      "Agree                        401\n",
      "Neither Agree Or Disagree    134\n",
      "Disagree                      42\n",
      "Strongly Disagree             10\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Exam_Explained value counts:\n",
      "Exam_Explained\n",
      "Strongly Agree               538\n",
      "Agree                        448\n",
      "Disagree                      50\n",
      "Neither Agree Or Disagree     10\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "LabTests_Explained value counts:\n",
      "LabTests_Explained\n",
      "Agree                        574\n",
      "Strongly Agree               448\n",
      "Disagree                      12\n",
      "Neither Agree Or Disagree     12\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Discuss_TreatOptions value counts:\n",
      "Discuss_TreatOptions\n",
      "Agree                        635\n",
      "Strongly Agree               392\n",
      "Neither Agree Or Disagree     10\n",
      "Disagree                       9\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Info_AsDesired value counts:\n",
      "Info_AsDesired\n",
      "Agree                        586\n",
      "Strongly Agree               375\n",
      "Disagree                      72\n",
      "Neither Agree Or Disagree     13\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Plan_Acceptability_Check value counts:\n",
      "Plan_Acceptability_Check\n",
      "Agree                        534\n",
      "Strongly Agree               409\n",
      "Neither Agree Or Disagree     84\n",
      "Disagree                      17\n",
      "Strongly Disagree              2\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Meds_Explained_SideFX value counts:\n",
      "Meds_Explained_SideFX\n",
      "Strongly Agree               502\n",
      "Agree                        477\n",
      "Neither Agree Or Disagree     37\n",
      "Disagree                      23\n",
      "Strongly Disagree              7\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Encourage_Questions value counts:\n",
      "Encourage_Questions\n",
      "Agree                        452\n",
      "Strongly Agree               447\n",
      "Disagree                      87\n",
      "Neither Agree Or Disagree     56\n",
      "Strongly Disagree              4\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Respond_Q_Concerns value counts:\n",
      "Respond_Q_Concerns\n",
      "Strongly Agree               498\n",
      "Agree                        386\n",
      "Disagree                      92\n",
      "Neither Agree Or Disagree     65\n",
      "Strongly Disagree              5\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Showed_Personal_Concern value counts:\n",
      "Showed_Personal_Concern\n",
      "Strongly Agree               478\n",
      "Agree                        423\n",
      "Disagree                      69\n",
      "Neither Agree Or Disagree     66\n",
      "Strongly Disagree             10\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Involved_In_Decisions value counts:\n",
      "Involved_In_Decisions\n",
      "Strongly Agree               498\n",
      "Agree                        482\n",
      "Neither Agree Or Disagree     63\n",
      "Disagree                       3\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Discuss_NextSteps value counts:\n",
      "Discuss_NextSteps\n",
      "Strongly Agree               543\n",
      "Agree                        459\n",
      "Neither Agree Or Disagree     44\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Checked_Understanding value counts:\n",
      "Checked_Understanding\n",
      "Strongly Agree               568\n",
      "Agree                        471\n",
      "Neither Agree Or Disagree      4\n",
      "Disagree                       2\n",
      "Strongly Disagree              1\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Time_Spent_Adequate value counts:\n",
      "Time_Spent_Adequate\n",
      "Strongly Agree               486\n",
      "Agree                        484\n",
      "Disagree                      40\n",
      "Neither Agree Or Disagree     36\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Visit_Satisfaction value counts:\n",
      "Visit_Satisfaction\n",
      "Very Satisfied       375\n",
      "Satisfied            326\n",
      "Neutral              181\n",
      "Very Dissatisfied    164\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Quick Frequency Check\n",
    "for col in likert_columns:\n",
    "    print(f\"\\n{col} value counts:\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08235c-c4de-4746-abf4-b5eafc451247",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78286bb2-af34-437d-ae11-7b2184efa110",
   "metadata": {},
   "source": [
    "### 1. Grouped Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13510b93-0666-4dd2-9a54-c0f72b4c2f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tertiary+' 'No formal' 'Primary/Secondary']\n"
     ]
    }
   ],
   "source": [
    "#@title Educational Level Grouping\n",
    "education_map = {\n",
    "    'No formal education': 'No formal',\n",
    "    'Primary education': 'Primary/Secondary',\n",
    "    'Secondary education': 'Primary/Secondary',\n",
    "    'Tertiary education (e.g., University, college)': 'Tertiary+',\n",
    "    'Postgraduate': 'Tertiary+', # If this value exists in your raw data but not unique(), keep it.\n",
    "    'Islamic education': 'No formal', # Or group as appropriate\n",
    "    'Diploma': 'Tertiary+', # Or group as appropriate\n",
    "    'Adult and non formal education': 'No formal' # Or group as appropriate\n",
    "}\n",
    "\n",
    "df['Education_Grouped'] = df['Educational Status'].map(education_map)\n",
    "\n",
    "# Now, this should show your grouped categories and potentially NaN if any new unmapped values appear\n",
    "print(df['Education_Grouped'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e08431a-e47b-45d5-af50-39f50164f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Informal' 'Unemployed' 'Formal' 'Other']\n"
     ]
    }
   ],
   "source": [
    "#@title Employment Grouping\n",
    "employment_map = {\n",
    "    'Unemployed': 'Unemployed',\n",
    "    'Self-employed': 'Informal',\n",
    "    'Employed part-time': 'Formal',  # Assuming part-time employment is formal\n",
    "    'Employed full-time': 'Formal',  # Assuming full-time employment is formal\n",
    "    'Other (please specify)': 'Other', # Grouping 'Other (please specify)' into 'Other'\n",
    "    'Retired': 'Other',\n",
    "    # If 'Informal', 'Government', 'Private', 'Student' don't exist in your raw 'Employment Status' column,\n",
    "    # you can remove them from the map, or keep them if they might appear in other data.\n",
    "    # For now, let's include only the ones found in your unique list.\n",
    "}\n",
    "\n",
    "df['Employment_Grouped'] = df['Employment Status'].map(employment_map)\n",
    "\n",
    "# Now, this should show your grouped categories without NaN (unless there are new unmapped values)\n",
    "print(df['Employment_Grouped'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f799dbc6-a3f7-45a4-b195-6817aae90c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Separated/Widowed' 'Single']\n"
     ]
    }
   ],
   "source": [
    "#@title Marital Grouping\n",
    "marital_map = {\n",
    "    'Single': 'Single',\n",
    "    'Married': 'Married',\n",
    "    'Divorced': 'Separated/Widowed',\n",
    "    'Widowed': 'Separated/Widowed',\n",
    "    'Seperated': 'Separated/Widowed' # Corrected spelling and mapping for your unique value\n",
    "}\n",
    "\n",
    "df['Marital_Grouped'] = df['Marital Status'].map(marital_map)\n",
    "\n",
    "# This should now show your grouped categories without NaN (unless new unmapped values appear)\n",
    "print(df['Marital_Grouped'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a45b17-0ef9-4e06-963b-ecd97f2f65ff",
   "metadata": {},
   "source": [
    "### 2. Duration Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "233598c8-a0cb-4297-a365-d425cdb3b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Duration Features\n",
    "df['HIV_Care_Duration_Ratio'] = df['HIV_Duration_Years'] / (df['Care_Duration_Years'] + 0.1)\n",
    "\n",
    "# Bucket Care Duration\n",
    "df['Care_Duration_Bucket'] = pd.cut(df['Care_Duration_Years'],\n",
    "                                     bins=[-np.inf, 1, 4, np.inf],\n",
    "                                     labels=['Short-term', 'Medium-term', 'Long-term'])\n",
    "\n",
    "# Interaction Terms\n",
    "df['Age_x_HIV_Duration'] = df['Age'] * df['HIV_Duration_Years']\n",
    "df['Income_x_Education'] = df['Monthly Income'].fillna(0) * df['Educational Status'].astype('category').cat.codes\n",
    "df['Gender_x_Employment'] = df['Gender'].astype(\n",
    "    'category').cat.codes * df['Employment Status'].astype('category').cat.codes\n",
    "df['Education_x_Employment'] = df['Educational Status'].astype(\n",
    "    'category').cat.codes * df['Employment Status'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a2517-8af5-4159-b644-5b99eba563de",
   "metadata": {},
   "source": [
    "### 3. Build subscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ef0f72-1a94-4cf1-93e3-fbbd20d9420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in subscores:\n",
      " Empathy_Score           0\n",
      "Listening_Score         0\n",
      "Decision_Share_Score    0\n",
      "Info_Delivery_Score     0\n",
      "dtype: int64\n",
      "\n",
      "Total rows with at least one missing subscore: 0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "#@title Step 1: Define your Likert-style columns\n",
    "# -----------------------------------------\n",
    "\n",
    "empathy_cols = [\n",
    "    'Showed_Personal_Concern',\n",
    "    'Greet_Comfort',\n",
    "    'Respond_Q_Concerns',\n",
    "    'Time_Spent_Adequate'\n",
    "]\n",
    "\n",
    "listening_cols = [\n",
    "    'Encourage_Thoughts',\n",
    "    'Listen_Careful',\n",
    "    'Understood_You'\n",
    "]\n",
    "\n",
    "decision_share_cols = [\n",
    "    'Involved_In_Decisions',\n",
    "    'Checked_Understanding',\n",
    "    'Encourage_Questions'\n",
    "]\n",
    "\n",
    "info_delivery_cols = [\n",
    "    'Discuss_VisitReason',\n",
    "    'Exam_Explained',\n",
    "    'LabTests_Explained',\n",
    "    'Discuss_TreatOptions',\n",
    "    'Meds_Explained_SideFX',\n",
    "    'Info_AsDesired',\n",
    "    'Plan_Acceptability_Check',\n",
    "    'Discuss_NextSteps'\n",
    "]\n",
    "\n",
    "# Combine all columns\n",
    "all_subscore_columns = empathy_cols + listening_cols + decision_share_cols + info_delivery_cols\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------\n",
    "#@title Step 2: Robust Likert Cleaner\n",
    "# -----------------------------------------\n",
    "\n",
    "def normalize_likert(val):\n",
    "    if pd.isnull(val):\n",
    "        return None\n",
    "    val = str(val).strip().lower()\n",
    "    # Corrected: Match against lowercase strings\n",
    "    if \"strongly agree\" in val:\n",
    "        return 5\n",
    "    elif val == \"agree\":\n",
    "        return 4\n",
    "    elif val == \"neither agree or disagree\":\n",
    "        return 3\n",
    "    elif \"strongly disagree\" in val: # Corrected: match against full phrase\n",
    "        return 1\n",
    "    elif \"disagree\" in val: # This should catch \"Disagree\" but not \"Strongly Disagree\" due to order\n",
    "        return 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------\n",
    "#@title Step 3: Apply cleaning to relevant columns\n",
    "# -----------------------------------------\n",
    "\n",
    "for col in all_subscore_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(normalize_likert)\n",
    "\n",
    "# -----------------------------------------\n",
    "#@title Step 4: Build subscores\n",
    "# -----------------------------------------\n",
    "df['Empathy_Score'] = df[empathy_cols].mean(axis=1)\n",
    "df['Listening_Score'] = df[listening_cols].mean(axis=1)\n",
    "df['Decision_Share_Score'] = df[decision_share_cols].mean(axis=1)\n",
    "df['Info_Delivery_Score'] = df[info_delivery_cols].mean(axis=1)\n",
    "\n",
    "# -----------------------------------------\n",
    "#@title Step 5: Check missing values in subscores\n",
    "# -----------------------------------------\n",
    "\n",
    "missing_subscores = df[[\n",
    "    'Empathy_Score',\n",
    "    'Listening_Score',\n",
    "    'Decision_Share_Score',\n",
    "    'Info_Delivery_Score'\n",
    "]].isnull().sum()\n",
    "\n",
    "print(\"Missing values in subscores:\\n\", missing_subscores)\n",
    "\n",
    "# Optional: see how many total rows are affected\n",
    "rows_missing = df[[\n",
    "    'Empathy_Score',\n",
    "    'Listening_Score',\n",
    "    'Decision_Share_Score',\n",
    "    'Info_Delivery_Score'\n",
    "]].isnull().any(axis=1).sum()\n",
    "print(f\"\\nTotal rows with at least one missing subscore: {rows_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67886b2a-2da2-4bf9-8711-0dbfac426a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 2, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Respond_Q_Concerns'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adffce-8bfd-4847-97a6-d4f417eddf05",
   "metadata": {},
   "source": [
    "### Check for duplicate patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d390579d-3375-4669-8311-526d4a2ab15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Identifying Duplicate Rows\n",
      "**Duplicate rows found (considering all columns EXCEPT 'EnumID'): 2**\n",
      "Here are the full rows from your original DataFrame that are considered duplicates:\n",
      "    EnumID State   Age  Gender Marital Status Family Setting  Num of Children  \\\n",
      "292   KN17  Kano  29.5  Female        Married       Monogamy              3.5   \n",
      "301  KN 17  Kano  29.5  Female        Married       Monogamy              3.5   \n",
      "\n",
      "      Educational Status Employment Status  Monthly Income  ...  \\\n",
      "292  No formal education     Self-employed         35000.0  ...   \n",
      "301  No formal education     Self-employed         35000.0  ...   \n",
      "\n",
      "    HIV_Care_Duration_Ratio  Care_Duration_Bucket  Age_x_HIV_Duration  \\\n",
      "292                0.952381           Medium-term                59.0   \n",
      "301                0.952381           Medium-term                59.0   \n",
      "\n",
      "     Income_x_Education Gender_x_Employment  Education_x_Employment  \\\n",
      "292            105000.0                   0                      12   \n",
      "301            105000.0                   0                      12   \n",
      "\n",
      "     Empathy_Score  Listening_Score  Decision_Share_Score  Info_Delivery_Score  \n",
      "292            5.0              5.0                   5.0                  5.0  \n",
      "301            5.0              5.0                   5.0                  5.0  \n",
      "\n",
      "[2 rows x 56 columns]\n",
      "\n",
      "## DataFrame after dropping duplicates:\n",
      "Original DataFrame shape: (1046, 56)\n",
      "Cleaned DataFrame shape: (1045, 56)\n",
      "             EnumID   State   Age  Gender Marital Status Family Setting  \\\n",
      "0     SYNTH-NEU-284  Jigawa  29.5  Female        Married       Monogamy   \n",
      "1             BC023  Bauchi  29.5  Female        Widowed       Polygamy   \n",
      "2     SYNTH-SAT-140  Jigawa  65.0  Female        Widowed       Monogamy   \n",
      "3              JG14  Jigawa  39.5  Female       Divorced       Monogamy   \n",
      "4     SYNTH-VER-519  Bauchi  39.5  Female         Single       Monogamy   \n",
      "...             ...     ...   ...     ...            ...            ...   \n",
      "1041          BC024  Bauchi  65.0  Female        Widowed       Monogamy   \n",
      "1042           KN06    Kano  39.5    Male        Married       Monogamy   \n",
      "1043           BC26  Bauchi  39.5  Female       Divorced       Monogamy   \n",
      "1044  SYNTH-VER-555  Bauchi  39.5  Female         Single       Polygamy   \n",
      "1045  SYNTH-NEU-371    Kano  29.5  Female         Single       Monogamy   \n",
      "\n",
      "      Num of Children                              Educational Status  \\\n",
      "0                 1.5  Tertiary education (e.g., University, college)   \n",
      "1                 5.0                             No formal education   \n",
      "2                 1.5                             Secondary education   \n",
      "3                 1.5                             Secondary education   \n",
      "4                 5.0                             Secondary education   \n",
      "...               ...                                             ...   \n",
      "1041              3.5                             No formal education   \n",
      "1042              1.5                             No formal education   \n",
      "1043              1.5                               Islamic education   \n",
      "1044              3.5                               Primary education   \n",
      "1045              1.5  Tertiary education (e.g., University, college)   \n",
      "\n",
      "           Employment Status  Monthly Income  ... HIV_Care_Duration_Ratio  \\\n",
      "0              Self-employed         10000.0  ...                0.158730   \n",
      "1              Self-employed         10000.0  ...               20.833333   \n",
      "2                 Unemployed         75500.0  ...                0.952381   \n",
      "3         Employed part-time         10000.0  ...                0.992063   \n",
      "4              Self-employed         10000.0  ...                0.989011   \n",
      "...                      ...             ...  ...                     ...   \n",
      "1041      Employed part-time         35000.0  ...                0.952381   \n",
      "1042  Other (please specify)         35000.0  ...                0.982143   \n",
      "1043           Self-employed         10000.0  ...                0.952381   \n",
      "1044           Self-employed         10000.0  ...                1.373626   \n",
      "1045           Self-employed        150500.0  ...                2.232143   \n",
      "\n",
      "      Care_Duration_Bucket  Age_x_HIV_Duration  Income_x_Education  \\\n",
      "0                Long-term               59.00             60000.0   \n",
      "1               Short-term              368.75             30000.0   \n",
      "2              Medium-term              130.00            377500.0   \n",
      "3                Long-term              493.75             50000.0   \n",
      "4                Long-term              355.50             50000.0   \n",
      "...                    ...                 ...                 ...   \n",
      "1041           Medium-term              130.00            105000.0   \n",
      "1042             Long-term              217.25            105000.0   \n",
      "1043           Medium-term               79.00             20000.0   \n",
      "1044             Long-term              493.75             40000.0   \n",
      "1045             Long-term              368.75            903000.0   \n",
      "\n",
      "     Gender_x_Employment  Education_x_Employment  Empathy_Score  \\\n",
      "0                      0                      24           3.25   \n",
      "1                      0                      12           3.50   \n",
      "2                      0                      25           3.50   \n",
      "3                      0                       5           5.00   \n",
      "4                      0                      20           5.00   \n",
      "...                  ...                     ...            ...   \n",
      "1041                   0                       3           5.00   \n",
      "1042                   2                       6           4.50   \n",
      "1043                   0                       8           3.00   \n",
      "1044                   0                      16           5.00   \n",
      "1045                   0                      24           4.00   \n",
      "\n",
      "      Listening_Score  Decision_Share_Score  Info_Delivery_Score  \n",
      "0            4.666667              4.000000                4.125  \n",
      "1            4.000000              3.666667                4.500  \n",
      "2            4.000000              4.000000                4.000  \n",
      "3            5.000000              5.000000                5.000  \n",
      "4            4.666667              4.666667                4.500  \n",
      "...               ...                   ...                  ...  \n",
      "1041         5.000000              5.000000                5.000  \n",
      "1042         4.000000              4.666667                4.625  \n",
      "1043         3.666667              3.333333                3.750  \n",
      "1044         4.666667              4.333333                4.375  \n",
      "1045         4.333333              4.000000                3.875  \n",
      "\n",
      "[1045 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "#@title Step 6: Check for duplicate patients\n",
    "# -----------------------------------------\n",
    "\n",
    "# Check if 'EnumID' column exists\n",
    "if 'EnumID' in df.columns:\n",
    "    # Create a temporary DataFrame by dropping 'EnumID' for the duplicate check\n",
    "    df_for_dup_check = df.drop(columns=['EnumID'])\n",
    "else:\n",
    "    # If 'EnumID' doesn't exist, use the entire DataFrame\n",
    "    df_for_dup_check = df.copy()\n",
    "\n",
    "## Step 1: Identify Duplicate Rows\n",
    "print(\"## Identifying Duplicate Rows\")\n",
    "# 'keep=False' marks all occurrences of a duplicate set as True\n",
    "dupes_found = df_for_dup_check[df_for_dup_check.duplicated(keep=False)]\n",
    "\n",
    "if not dupes_found.empty:\n",
    "    print(f\"**Duplicate rows found (considering all columns EXCEPT 'EnumID'): {len(dupes_found)}**\")\n",
    "    print(\"Here are the full rows from your original DataFrame that are considered duplicates:\")\n",
    "    # Use the index from 'dupes_found' to select corresponding rows from the original 'df'\n",
    "    print(df.loc[dupes_found.index])\n",
    "else:\n",
    "    print(\"**No duplicate rows found (excluding 'EnumID').**\")\n",
    "\n",
    "## Step 2: Drop Duplicates\n",
    "\n",
    "# Drop duplicates based on all columns EXCEPT 'EnumID'\n",
    "# 'keep='first'' will keep the first occurrence of each duplicate set\n",
    "if 'EnumID' in df.columns:\n",
    "    # Get columns to consider for dropping duplicates (all except 'EnumID')\n",
    "    columns_to_consider = [col for col in df.columns if col != 'EnumID']\n",
    "    df_cleaned = df.drop_duplicates(subset=columns_to_consider, keep='first')\n",
    "else:\n",
    "    # If 'EnumID' doesn't exist, drop duplicates based on all columns\n",
    "    df_cleaned = df.drop_duplicates(keep='first')\n",
    "\n",
    "\n",
    "print(\"\\n## DataFrame after dropping duplicates:\")\n",
    "print(f\"Original DataFrame shape: {df.shape}\")\n",
    "print(f\"Cleaned DataFrame shape: {df_cleaned.shape}\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22279110-b9d9-4fa0-83c6-25fd1fc22e3c",
   "metadata": {},
   "source": [
    "### Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479b1c1f-cfda-48b9-9d7f-a7894e20c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/2_nndwys2mvfzn_vvr5fx67h0000gn/T/ipykernel_60621/3087073871.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.loc[:, \"Empathy_Listening_Interaction\"] = df_cleaned[\"Empathy_Score\"] * df_cleaned[\"Listening_Score\"]\n",
      "/var/folders/wl/2_nndwys2mvfzn_vvr5fx67h0000gn/T/ipykernel_60621/3087073871.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.loc[:, \"Empathy_DecisionShare_Interaction\"] = df_cleaned[\"Empathy_Score\"] * df_cleaned[\"Decision_Share_Score\"]\n"
     ]
    }
   ],
   "source": [
    "#@title Interaction Features\n",
    "# Using .loc for explicit assignment\n",
    "df_cleaned.loc[:, \"Empathy_Listening_Interaction\"] = df_cleaned[\"Empathy_Score\"] * df_cleaned[\"Listening_Score\"]\n",
    "df_cleaned.loc[:, \"Empathy_DecisionShare_Interaction\"] = df_cleaned[\"Empathy_Score\"] * df_cleaned[\"Decision_Share_Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87fa9e-33b1-40c0-9174-9d122fa1b078",
   "metadata": {},
   "source": [
    "### Aggregate Behavioral Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e90e265-e953-4068-88eb-c2c620d54347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "#@title Aggregate Behavioral Profiles\n",
    "# All_High_Satisfaction: whether all Likert items were 4 or 5.\n",
    "# Any_Dissatisfaction: whether any of the core variables are below 3.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "core_likert = ['Empathy_Score', 'Listening_Score',\n",
    "               'Decision_Share_Score', 'Info_Delivery_Score']\n",
    "df[\"All_High_Satisfaction\"] = (df[core_likert] >= 4).all(axis=1).astype(int)\n",
    "df[\"Any_Low_Score\"] = (df[core_likert] < 3).any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b58cad-6cd4-4390-935a-9bf38403a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/2_nndwys2mvfzn_vvr5fx67h0000gn/T/ipykernel_60621/1351518969.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned.rename(columns={'Visit_Satisfaction': 'Satisfaction'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['EnumID', 'State', 'Age', 'Gender', 'Marital Status', 'Family Setting',\n",
       "       'Num of Children', 'Educational Status', 'Employment Status',\n",
       "       'Monthly Income', 'Treatment Regimen', 'HIV_Duration_Years',\n",
       "       'Care_Duration_Years', 'Facility_Care_Dur_Years', 'HIV_Diag_Type',\n",
       "       'Greet_Comfort', 'Discuss_VisitReason', 'Encourage_Thoughts',\n",
       "       'Listen_Careful', 'Understood_You', 'Exam_Explained',\n",
       "       'LabTests_Explained', 'Discuss_TreatOptions', 'Info_AsDesired',\n",
       "       'Plan_Acceptability_Check', 'Meds_Explained_SideFX',\n",
       "       'Encourage_Questions', 'Respond_Q_Concerns', 'Showed_Personal_Concern',\n",
       "       'Involved_In_Decisions', 'Discuss_NextSteps', 'Checked_Understanding',\n",
       "       'Time_Spent_Adequate', 'Satisfaction', 'Source',\n",
       "       'Monthly_Income_Missing', 'Age_zscore', 'Num of Children_zscore',\n",
       "       'Monthly Income_zscore', 'HIV_Duration_Years_zscore',\n",
       "       'Care_Duration_Years_zscore', 'Facility_Care_Dur_Years_zscore',\n",
       "       'Monthly Income_log', 'Education_Grouped', 'Employment_Grouped',\n",
       "       'Marital_Grouped', 'HIV_Care_Duration_Ratio', 'Care_Duration_Bucket',\n",
       "       'Age_x_HIV_Duration', 'Income_x_Education', 'Gender_x_Employment',\n",
       "       'Education_x_Employment', 'Empathy_Score', 'Listening_Score',\n",
       "       'Decision_Share_Score', 'Info_Delivery_Score',\n",
       "       'Empathy_Listening_Interaction', 'Empathy_DecisionShare_Interaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the column\n",
    "df_cleaned.rename(columns={'Visit_Satisfaction': 'Satisfaction'}, inplace=True)\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4929ff-4c7a-4a36-8413-dbe2e06714a1",
   "metadata": {},
   "source": [
    "### Remove redundant features to reduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb78da46-feed-421b-9a9e-81ec5689a62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 36\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "#@title Remove redundant features to reduce noise\n",
    "# -----------------------------------------------\n",
    "\n",
    "# List of features to drop\n",
    "features_to_drop = [\n",
    "    'EnumID', 'Source', 'Visit_Satisfaction', 'Monthly_Income_Missing',\n",
    "    'Age_zscore', 'Num of Children_zscore', 'Monthly Income_zscore',\n",
    "    'HIV_Duration_Years_zscore', 'Care_Duration_Years_zscore', 'Facility_Care_Dur_Years_zscore',\n",
    "    'Educational Status', 'Employment Status', 'Marital Status',\n",
    "    'Age', 'Monthly Income', 'Num of Children', 'Care_Duration_Bucket',\n",
    "    'Income_x_Education', 'Gender_x_Employment', 'Education_x_Employment',\n",
    "    'HIV_Duration_Years', 'Care_Duration_Years', 'Facility_Care_Dur_Years'\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "df_engineered = df_cleaned.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "# Confirm shape after drop (optional)\n",
    "print(f\"Remaining columns: {df_engineered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d4e57b9-725c-4502-a699-2d36be008841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'Gender', 'Family Setting', 'Treatment Regimen',\n",
       "       'HIV_Diag_Type', 'Greet_Comfort', 'Discuss_VisitReason',\n",
       "       'Encourage_Thoughts', 'Listen_Careful', 'Understood_You',\n",
       "       'Exam_Explained', 'LabTests_Explained', 'Discuss_TreatOptions',\n",
       "       'Info_AsDesired', 'Plan_Acceptability_Check', 'Meds_Explained_SideFX',\n",
       "       'Encourage_Questions', 'Respond_Q_Concerns', 'Showed_Personal_Concern',\n",
       "       'Involved_In_Decisions', 'Discuss_NextSteps', 'Checked_Understanding',\n",
       "       'Time_Spent_Adequate', 'Satisfaction', 'Monthly Income_log',\n",
       "       'Education_Grouped', 'Employment_Grouped', 'Marital_Grouped',\n",
       "       'HIV_Care_Duration_Ratio', 'Age_x_HIV_Duration', 'Empathy_Score',\n",
       "       'Listening_Score', 'Decision_Share_Score', 'Info_Delivery_Score',\n",
       "       'Empathy_Listening_Interaction', 'Empathy_DecisionShare_Interaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engineered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5a745a-64bd-4acf-a8f0-5f854f31560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Family Setting</th>\n",
       "      <th>Treatment Regimen</th>\n",
       "      <th>HIV_Diag_Type</th>\n",
       "      <th>Greet_Comfort</th>\n",
       "      <th>Discuss_VisitReason</th>\n",
       "      <th>Encourage_Thoughts</th>\n",
       "      <th>Listen_Careful</th>\n",
       "      <th>Understood_You</th>\n",
       "      <th>...</th>\n",
       "      <th>Employment_Grouped</th>\n",
       "      <th>Marital_Grouped</th>\n",
       "      <th>HIV_Care_Duration_Ratio</th>\n",
       "      <th>Age_x_HIV_Duration</th>\n",
       "      <th>Empathy_Score</th>\n",
       "      <th>Listening_Score</th>\n",
       "      <th>Decision_Share_Score</th>\n",
       "      <th>Info_Delivery_Score</th>\n",
       "      <th>Empathy_Listening_Interaction</th>\n",
       "      <th>Empathy_DecisionShare_Interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jigawa</td>\n",
       "      <td>Female</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Informal</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>59.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.125</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bauchi</td>\n",
       "      <td>Female</td>\n",
       "      <td>Polygamy</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>Do not know</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Informal</td>\n",
       "      <td>Separated/Widowed</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>368.75</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.500</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jigawa</td>\n",
       "      <td>Female</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>Not sure</td>\n",
       "      <td>Do not know</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Separated/Widowed</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>130.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jigawa</td>\n",
       "      <td>Female</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>First-line regimen</td>\n",
       "      <td>Both HIV-1 and HIV-2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Separated/Widowed</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>493.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bauchi</td>\n",
       "      <td>Female</td>\n",
       "      <td>Monogamy</td>\n",
       "      <td>First-line regimen</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Informal</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>355.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.500</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>23.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  Gender Family Setting   Treatment Regimen         HIV_Diag_Type  \\\n",
       "0  Jigawa  Female       Monogamy            Not sure                 HIV-1   \n",
       "1  Bauchi  Female       Polygamy            Not sure           Do not know   \n",
       "2  Jigawa  Female       Monogamy            Not sure           Do not know   \n",
       "3  Jigawa  Female       Monogamy  First-line regimen  Both HIV-1 and HIV-2   \n",
       "4  Bauchi  Female       Monogamy  First-line regimen                 HIV-1   \n",
       "\n",
       "   Greet_Comfort  Discuss_VisitReason  Encourage_Thoughts  Listen_Careful  \\\n",
       "0              1                    4                   5               4   \n",
       "1              4                    4                   4               4   \n",
       "2              4                    4                   4               4   \n",
       "3              5                    5                   5               5   \n",
       "4              5                    5                   5               4   \n",
       "\n",
       "   Understood_You  ...  Employment_Grouped    Marital_Grouped  \\\n",
       "0               5  ...            Informal            Married   \n",
       "1               4  ...            Informal  Separated/Widowed   \n",
       "2               4  ...          Unemployed  Separated/Widowed   \n",
       "3               5  ...              Formal  Separated/Widowed   \n",
       "4               5  ...            Informal             Single   \n",
       "\n",
       "   HIV_Care_Duration_Ratio  Age_x_HIV_Duration  Empathy_Score  \\\n",
       "0                 0.158730               59.00           3.25   \n",
       "1                20.833333              368.75           3.50   \n",
       "2                 0.952381              130.00           3.50   \n",
       "3                 0.992063              493.75           5.00   \n",
       "4                 0.989011              355.50           5.00   \n",
       "\n",
       "   Listening_Score  Decision_Share_Score  Info_Delivery_Score  \\\n",
       "0         4.666667              4.000000                4.125   \n",
       "1         4.000000              3.666667                4.500   \n",
       "2         4.000000              4.000000                4.000   \n",
       "3         5.000000              5.000000                5.000   \n",
       "4         4.666667              4.666667                4.500   \n",
       "\n",
       "   Empathy_Listening_Interaction  Empathy_DecisionShare_Interaction  \n",
       "0                      15.166667                          13.000000  \n",
       "1                      14.000000                          12.833333  \n",
       "2                      14.000000                          14.000000  \n",
       "3                      25.000000                          25.000000  \n",
       "4                      23.333333                          23.333333  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engineered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af5219da-349b-467e-9af1-b18b121c9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1045 entries, 0 to 1045\n",
      "Data columns (total 36 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   State                              1045 non-null   object \n",
      " 1   Gender                             1045 non-null   object \n",
      " 2   Family Setting                     1045 non-null   object \n",
      " 3   Treatment Regimen                  1045 non-null   object \n",
      " 4   HIV_Diag_Type                      1045 non-null   object \n",
      " 5   Greet_Comfort                      1045 non-null   int64  \n",
      " 6   Discuss_VisitReason                1045 non-null   int64  \n",
      " 7   Encourage_Thoughts                 1045 non-null   int64  \n",
      " 8   Listen_Careful                     1045 non-null   int64  \n",
      " 9   Understood_You                     1045 non-null   int64  \n",
      " 10  Exam_Explained                     1045 non-null   int64  \n",
      " 11  LabTests_Explained                 1045 non-null   int64  \n",
      " 12  Discuss_TreatOptions               1045 non-null   int64  \n",
      " 13  Info_AsDesired                     1045 non-null   int64  \n",
      " 14  Plan_Acceptability_Check           1045 non-null   int64  \n",
      " 15  Meds_Explained_SideFX              1045 non-null   int64  \n",
      " 16  Encourage_Questions                1045 non-null   int64  \n",
      " 17  Respond_Q_Concerns                 1045 non-null   int64  \n",
      " 18  Showed_Personal_Concern            1045 non-null   int64  \n",
      " 19  Involved_In_Decisions              1045 non-null   int64  \n",
      " 20  Discuss_NextSteps                  1045 non-null   int64  \n",
      " 21  Checked_Understanding              1045 non-null   int64  \n",
      " 22  Time_Spent_Adequate                1045 non-null   int64  \n",
      " 23  Satisfaction                       1045 non-null   object \n",
      " 24  Monthly Income_log                 1045 non-null   float64\n",
      " 25  Education_Grouped                  1045 non-null   object \n",
      " 26  Employment_Grouped                 1045 non-null   object \n",
      " 27  Marital_Grouped                    1045 non-null   object \n",
      " 28  HIV_Care_Duration_Ratio            1045 non-null   float64\n",
      " 29  Age_x_HIV_Duration                 1045 non-null   float64\n",
      " 30  Empathy_Score                      1045 non-null   float64\n",
      " 31  Listening_Score                    1045 non-null   float64\n",
      " 32  Decision_Share_Score               1045 non-null   float64\n",
      " 33  Info_Delivery_Score                1045 non-null   float64\n",
      " 34  Empathy_Listening_Interaction      1045 non-null   float64\n",
      " 35  Empathy_DecisionShare_Interaction  1045 non-null   float64\n",
      "dtypes: float64(9), int64(18), object(9)\n",
      "memory usage: 302.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_engineered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7c5d7-fc72-43eb-8d8c-af929d16edf9",
   "metadata": {},
   "source": [
    "### Install and import packages and libraries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "929bc0ed-e326-4268-bb44-13abf0d77648",
   "metadata": {},
   "source": [
    "# Force installation in the current kernel's environment\n",
    "# The > /dev/null 2>&1 just hides the output for a cleaner notebook\n",
    "!pip install catboost > /dev/null 2>&1\n",
    "!pip install shap > /dev/null 2>&1\n",
    "!pip install xgboost > /dev/null 2>&1\n",
    "!pip install lightgbm > /dev/null 2>&1\n",
    "\n",
    "print(\"All libraries have been installed. Please restart the kernel.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77e9a374-c03d-42cf-9d9e-83e7c1414278",
   "metadata": {},
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 1. Get the path to the Python executable of the current kernel\n",
    "python_executable = sys.executable\n",
    "print(f\"The current Jupyter kernel is running from: {python_executable}\")\n",
    "\n",
    "# 2. Use the kernel's Python executable to call pip and install catboost\n",
    "print(\"\\nInstalling 'catboost' into the current kernel's environment...\")\n",
    "try:\n",
    "    subprocess.check_call([python_executable, '-m', 'pip', 'install', 'catboost'])\n",
    "    print(\"'catboost' installed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error during installation: {e}\")\n",
    "    print(\"Please check for permission issues or other package conflicts.\")\n",
    "\n",
    "# 3. List the installed packages to verify\n",
    "print(\"\\nChecking the installed packages in the current environment:\")\n",
    "subprocess.run([python_executable, '-m', 'pip', 'list'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"ACTION REQUIRED: Restart your Jupyter kernel now.\")\n",
    "print(\"Once restarted, the 'catboost' module will be available.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c8c48d1-26cd-4c0a-8da7-739275543ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FutureWarnings are now ignored.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "#@title ✅ Import libraries\n",
    "# ------------------------------------------------------------------\n",
    "import shap\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "\n",
    "# Suppress SettingWithCopyWarning for cleaner output\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print(\"FutureWarnings are now ignored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7825a72f-9614-475a-8c4d-4a62370757c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (836, 35)\n",
      "Shape of X_test: (209, 35)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# @title ✅ Split, then Preprocess\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Split Features and Target\n",
    "X = df_engineered.drop(columns=['Satisfaction']) # Features\n",
    "y = df_engineered['Satisfaction']                 # Target\n",
    "\n",
    "# Step 2: Split the data into Training and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7588d05b-97fd-46c6-85da-080a6584ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with encoded categorical features (first 5 rows):\n",
      "     State  Gender  Family Setting  Treatment Regimen  HIV_Diag_Type  \\\n",
      "140    1.0     0.0             0.0                0.0            1.0   \n",
      "274    0.0     0.0             1.0                1.0            1.0   \n",
      "531    0.0     1.0             0.0                0.0            2.0   \n",
      "227    2.0     0.0             0.0                1.0            4.0   \n",
      "263    2.0     0.0             0.0                0.0            1.0   \n",
      "\n",
      "     Greet_Comfort  Discuss_VisitReason  Encourage_Thoughts  Listen_Careful  \\\n",
      "140              4                    4                   5               4   \n",
      "274              1                    5                   5               5   \n",
      "531              5                    5                   5               5   \n",
      "227              4                    4                   5               5   \n",
      "263              4                    5                   3               5   \n",
      "\n",
      "     Understood_You  ...  Employment_Grouped  Marital_Grouped  \\\n",
      "140               4  ...                 0.0              2.0   \n",
      "274               5  ...                 3.0              1.0   \n",
      "531               5  ...                 1.0              2.0   \n",
      "227               3  ...                 1.0              0.0   \n",
      "263               5  ...                 1.0              1.0   \n",
      "\n",
      "     HIV_Care_Duration_Ratio  Age_x_HIV_Duration  Empathy_Score  \\\n",
      "140                 9.166667              357.50           3.75   \n",
      "274                 0.992063              812.50           4.00   \n",
      "531                 0.992063              493.75           5.00   \n",
      "227                 0.436508              162.25           3.75   \n",
      "263                 0.992063              493.75           4.00   \n",
      "\n",
      "     Listening_Score  Decision_Share_Score  Info_Delivery_Score  \\\n",
      "140         4.333333              4.333333                3.625   \n",
      "274         5.000000              5.000000                5.000   \n",
      "531         5.000000              5.000000                4.250   \n",
      "227         4.333333              4.333333                4.375   \n",
      "263         4.333333              4.000000                4.375   \n",
      "\n",
      "     Empathy_Listening_Interaction  Empathy_DecisionShare_Interaction  \n",
      "140                      16.250000                              16.25  \n",
      "274                      20.000000                              20.00  \n",
      "531                      25.000000                              25.00  \n",
      "227                      16.250000                              16.25  \n",
      "263                      17.333333                              16.00  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# @title ✅ Encoding and Preprocessing for Features (X)\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# Identify categorical columns in the TRAINING set ONLY\n",
    "categorical_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Define the OrdinalEncoder for features\n",
    "# This encoder will be fitted on X_train and then used to transform both X_train and X_test\n",
    "feature_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit the encoder ON THE TRAINING DATA ONLY and then transform both sets\n",
    "X_train[categorical_cols] = feature_encoder.fit_transform(X_train[categorical_cols])\n",
    "X_test[categorical_cols] = feature_encoder.transform(X_test[categorical_cols])\n",
    "\n",
    "print(\"X_train with encoded categorical features (first 5 rows):\")\n",
    "print(X_train.head())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70a89720-b477-4539-bae1-64ee095e88f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y_train values (first 10):\n",
      "['Satisfied' 'Very Satisfied' 'Very Dissatisfied' 'Neutral' 'Neutral'\n",
      " 'Neutral' 'Satisfied' 'Very Satisfied' 'Very Satisfied' 'Very Satisfied']\n",
      "\n",
      "Encoded y_train values (used for model training, first 10):\n",
      "[3. 4. 0. 2. 2. 2. 3. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# @title ✅ Encoding for Target (y)\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# Define the explicit order of categories for the target variable\n",
    "# This is crucial for consistency.\n",
    "satisfaction_order = [\"Very Dissatisfied\", \"Not Satisfied\", \"Neutral\", \"Satisfied\", \"Very Satisfied\"]\n",
    "\n",
    "# Create a separate encoder for the target variable\n",
    "target_encoder = OrdinalEncoder(categories=[satisfaction_order])\n",
    "\n",
    "# Fit the target encoder ON THE TRAINING DATA ONLY\n",
    "target_encoder.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Transform both training and test target data using the FITTED encoder\n",
    "y_train_encoded = target_encoder.transform(y_train.values.reshape(-1, 1))\n",
    "y_test_encoded = target_encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "print(\"Original y_train values (first 10):\")\n",
    "print(y_train.values.flatten()[:10])\n",
    "print(\"\\nEncoded y_train values (used for model training, first 10):\")\n",
    "print(y_train_encoded.flatten()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba0f2c7c-85d9-40b5-8a92-4669fb461361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (as np.float64 array):\n",
      "[1.44337017 0.80138037 1.5929878  0.69852941]\n",
      "Class weights (as dictionary):\n",
      "{'Neutral': np.float64(1.4433701657458564), 'Satisfied': np.float64(0.8013803680981595), 'Very Dissatisfied': np.float64(1.5929878048780488), 'Very Satisfied': np.float64(0.6985294117647058)}\n",
      "\n",
      "Class weights (as standard Python floats):\n",
      "{'Neutral': 1.4433701657458564, 'Satisfied': 0.8013803680981595, 'Very Dissatisfied': 1.5929878048780488, 'Very Satisfied': 0.6985294117647058}\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# @title ✅ Compute Class Weights\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# CRITICAL: Use ONLY y_train to compute class weights.\n",
    "# y_train is the target variable from your training set after the split.\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# This will produce an array of np.float64\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "print(\"Class weights (as np.float64 array):\")\n",
    "print(class_weights)\n",
    "print(\"Class weights (as dictionary):\")\n",
    "print(class_weight_dict)\n",
    "\n",
    "# --- Optional Conversion to standard Python floats ---\n",
    "class_weight_dict_scalar = {k: float(v) for k, v in class_weight_dict.items()}\n",
    "print(\"\\nClass weights (as standard Python floats):\")\n",
    "print(class_weight_dict_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b7ba484-ccff-4ad4-b0b9-cc33acb37e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={&#x27;Neutral&#x27;: np.float64(1.4433701657458564),\n",
       "                                     &#x27;Satisfied&#x27;: np.float64(0.8013803680981595),\n",
       "                                     &#x27;Very Dissatisfied&#x27;: np.float64(1.5929878048780488),\n",
       "                                     &#x27;Very Satisfied&#x27;: np.float64(0.6985294117647058)},\n",
       "                       max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={&#x27;Neutral&#x27;: np.float64(1.4433701657458564),\n",
       "                                     &#x27;Satisfied&#x27;: np.float64(0.8013803680981595),\n",
       "                                     &#x27;Very Dissatisfied&#x27;: np.float64(1.5929878048780488),\n",
       "                                     &#x27;Very Satisfied&#x27;: np.float64(0.6985294117647058)},\n",
       "                       max_depth=10, n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={'Neutral': np.float64(1.4433701657458564),\n",
       "                                     'Satisfied': np.float64(0.8013803680981595),\n",
       "                                     'Very Dissatisfied': np.float64(1.5929878048780488),\n",
       "                                     'Very Satisfied': np.float64(0.6985294117647058)},\n",
       "                       max_depth=10, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "#@title 🔹 Random Forest\n",
    "# -------------------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    max_depth=10\n",
    ")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be149203-0a5c-4207-9d5a-f6901972efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "#@title 🔹 XGBOOST\n",
    "# -------------------------------------------\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "sample_weights = y_train.map(class_weight_dict)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb.fit(X_train, y_train_encoded, sample_weight=sample_weights)\n",
    "\n",
    "class_mapping = dict(zip(le.transform(le.classes_), le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc245596-79b0-4310-9ecc-bb3edfd8968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM model training completed. The training output was suppressed.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "#@title 🔹 LightGBM\n",
    "# -------------------------------------------\n",
    "\n",
    "# Use verbose=-1 to suppress training output\n",
    "lgbm = lgb.LGBMClassifier(class_weight=class_weight_dict, random_state=42, verbose=-1)\n",
    "\n",
    "# The .fit() method now works without the verbose argument\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nLightGBM model training completed. The training output was suppressed.\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc14482b-6682-41c9-9229-5ef9b4ddffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating RandomForest...\n",
      "✅ Accuracy: 0.8019, F1-weighted: 0.8032, Log Loss: 0.5433\n",
      "\n",
      "🔍 Evaluating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [14:16:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.8201, F1-weighted: 0.8198, Log Loss: 0.4899\n",
      "\n",
      "🔍 Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.8278, F1-weighted: 0.8272, Log Loss: 0.4829\n",
      "\n",
      "🏆 Best model based on weighted F1-score: LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ✅ Full Model Evaluation and Selection Based on Performance\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Evaluation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Encode target for models like XGBoost\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Scoring dict for cross_validate\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_weighted': 'f1_weighted'\n",
    "}\n",
    "\n",
    "# Define the Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define models, wrapped in a Pipeline\n",
    "models_to_evaluate = {\n",
    "    'RandomForest': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(class_weight=class_weight_dict, random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(eval_metric='mlogloss', random_state=42, use_label_encoder=False))\n",
    "    ]),\n",
    "    'LightGBM': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LGBMClassifier(class_weight=class_weight_dict, random_state=42, verbose=-1))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models_to_evaluate.items():\n",
    "    print(f\"\\n🔍 Evaluating {name}...\")\n",
    "\n",
    "    if name == 'XGBoost':\n",
    "        y_input = y_encoded\n",
    "    else:\n",
    "        y_input = y\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y_input,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_estimator=True\n",
    "    )\n",
    "\n",
    "    acc = np.mean(cv_results['test_accuracy'])\n",
    "    f1w = np.mean(cv_results['test_f1_weighted'])\n",
    "\n",
    "    logloss_vals = []\n",
    "    for estimator, (_, test_idx) in zip(cv_results['estimator'], cv.split(X, y_input)):\n",
    "        # This part is correct: X is a pandas DataFrame so .iloc is the right way.\n",
    "        X_test_fold = X.iloc[test_idx]\n",
    "\n",
    "        # Use conditional logic to ensure the correct indexing method is used for y_input\n",
    "        if isinstance(y_input, pd.Series):\n",
    "            y_test_fold = y_input.iloc[test_idx]\n",
    "        else:\n",
    "            # For XGBoost, y_input is a NumPy array, so standard indexing works fine.\n",
    "            y_test_fold = y_input[test_idx]\n",
    "        \n",
    "        try:\n",
    "            y_proba = estimator.predict_proba(X_test_fold)\n",
    "            logloss_vals.append(log_loss(y_test_fold, y_proba))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {name} failed log_loss on one fold: {e}\")\n",
    "            logloss_vals.append(np.nan)\n",
    "\n",
    "    logloss = np.nanmean(logloss_vals)\n",
    "\n",
    "    print(f\"✅ Accuracy: {acc:.4f}, F1-weighted: {f1w:.4f}, Log Loss: {logloss:.4f}\")\n",
    "\n",
    "    results.append((name, {'accuracy': acc, 'f1_weighted': f1w, 'log_loss': logloss}))\n",
    "    \n",
    "# Select best model\n",
    "best_model = max(results, key=lambda x: x[1]['f1_weighted'])\n",
    "print(f\"\\n🏆 Best model based on weighted F1-score: {best_model[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12ff7217-993e-4dc1-935f-e5b2b012debe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 159\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(logs_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# --------------------------------------------\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# ✅ CALL FUNCTION TO GENERATE OUTPUT\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# --------------------------------------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# label_encoder (your fitted LabelEncoder for y)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# target_encoder (your fitted OrdinalEncoder for y)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m run_explanations_for_lgbm(\n\u001b[1;32m    156\u001b[0m     model\u001b[38;5;241m=\u001b[39mlgbm,\n\u001b[1;32m    157\u001b[0m     X_test\u001b[38;5;241m=\u001b[39mX_test,\n\u001b[1;32m    158\u001b[0m     openrouter_api_key\u001b[38;5;241m=\u001b[39mopenrouter_api_key,\n\u001b[0;32m--> 159\u001b[0m     label_encoder\u001b[38;5;241m=\u001b[39m\u001b[43mlabel_encoder\u001b[49m,\n\u001b[1;32m    160\u001b[0m     target_encoder\u001b[38;5;241m=\u001b[39mtarget_encoder,\n\u001b[1;32m    161\u001b[0m     max_instances\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    162\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# ✅ SHAP + EXPLANATION PIPELINE (CATBOOST ONLY)\n",
    "# --------------------------------------------\n",
    "\n",
    "# --- LLM API Key (Keep this secure!) ---\n",
    "openrouter_api_key = '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'\n",
    "\n",
    "# --- GLOBAL LOG DATAFRAME ---\n",
    "# This DataFrame will store the explanation logs\n",
    "logs_df = pd.DataFrame(columns=[\n",
    "    'instance_idx', 'prediction', 'confidence', 'top_features',\n",
    "    'reason', 'suggestions', 'genai_explanation'\n",
    "])\n",
    "\n",
    "# --- RULE DEFINITIONS ---\n",
    "def rule_empathy(shap_scores):\n",
    "    return shap_scores.get('Empathy_Score', 3) < 2.5\n",
    "\n",
    "def rule_decision_sharing(shap_scores):\n",
    "    return shap_scores.get('Decision_Share_Score', 3) < 2.5\n",
    "\n",
    "def rule_listening(shap_scores):\n",
    "    return shap_scores.get('Listening_Score', 3) < 3\n",
    "\n",
    "RULES = [\n",
    "    ('Empathy was low', \"Enhance provider's empathetic communication\", rule_empathy),\n",
    "    ('Decision-sharing was low', \"Improve patient engagement in decisions\", rule_decision_sharing),\n",
    "    ('Listening was moderate', \"Train providers on active listening techniques\", rule_listening),\n",
    "]\n",
    "\n",
    "# --- SHAP EXPLAINER FUNCTION ---\n",
    "# For LightGBM, TreeExplainer works directly on the model\n",
    "def get_shap_explainer(model):\n",
    "    return shap.TreeExplainer(model)\n",
    "\n",
    "# --- DEEPSEEK EXPLANATION FUNCTION ---\n",
    "def deepseek_generate_explanation(prediction, confidence, top_features, reasons, suggestions, openrouter_api_key):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI assistant helping a healthcare team understand why a specific HIV client was predicted to be '{prediction}' with {confidence}% confidence.\n",
    "\n",
    "Top contributing factors:\n",
    "{json.dumps(top_features, indent=2)}\n",
    "\n",
    "Rule-based issues:\n",
    "{reasons}\n",
    "\n",
    "Suggestions for improvement:\n",
    "{suggestions}\n",
    "\n",
    "Based on:\n",
    "- Respectful provider communication, use of local language\n",
    "- DSD models (MMD, fast track, reduced wait)\n",
    "- Higher satisfaction with complex ART regimens, moderate income\n",
    "- Lower satisfaction with polygamous families, long treatment, poor decision involvement, fragmented services\n",
    "\n",
    "Write a concise explanation for clinical quality improvement.\n",
    "\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {openrouter_api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    body = {\n",
    "        \"model\": \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                                 headers=headers, data=json.dumps(body))\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return \"LLM error: \" + response.text\n",
    "    except Exception as e:\n",
    "        return f\"Exception: {e}\"\n",
    "\n",
    "# --- MAIN PREDICTION EXPLANATION FUNCTION (ADAPTED FOR LIGHTGBM) ---\n",
    "def explain_lgbm_prediction(instance_idx, model, X_test_transformed, openrouter_api_key, label_encoder, target_encoder):\n",
    "    global logs_df\n",
    "\n",
    "    instance = X_test_transformed.iloc[instance_idx:instance_idx+1]\n",
    "    explainer = get_shap_explainer(model)\n",
    "    shap_vals = explainer.shap_values(instance)\n",
    "\n",
    "    preds_proba = model.predict_proba(instance)[0]\n",
    "    pred_class_encoded = np.argmax(preds_proba)\n",
    "    confidence_val = round(float(np.max(preds_proba)) * 100, 1)\n",
    "\n",
    "    pred_class_text = target_encoder.inverse_transform([[pred_class_encoded]])[0][0]\n",
    "\n",
    "    shap_vals_for_predicted_class = shap_vals[pred_class_encoded][0]\n",
    "    shap_dict = dict(zip(X_test_transformed.columns, shap_vals_for_predicted_class))\n",
    "    top_features = dict(sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True)[:3])\n",
    "    top_features = {k: round(float(v), 1) for k, v in top_features.items()}\n",
    "\n",
    "    shap_scores = {\n",
    "        'Empathy_Score': instance['Empathy_Score'].iloc[0],\n",
    "        'Decision_Share_Score': instance['Decision_Share_Score'].iloc[0],\n",
    "        'Listening_Score': instance['Listening_Score'].iloc[0],\n",
    "    }\n",
    "\n",
    "    reasons, suggestions = [], []\n",
    "    for reason_text, suggestion_text, rule_fn in RULES:\n",
    "        if rule_fn(shap_scores):\n",
    "            reasons.append(reason_text)\n",
    "            suggestions.append(suggestion_text)\n",
    "\n",
    "    explanation_text = deepseek_generate_explanation(\n",
    "        pred_class_text, confidence_val, top_features, reasons, suggestions,\n",
    "        openrouter_api_key=openrouter_api_key\n",
    "    )\n",
    "\n",
    "    log_entry = {\n",
    "        'instance_idx': instance_idx,\n",
    "        'prediction': pred_class_text,\n",
    "        'confidence': f\"{confidence_val}%\",\n",
    "        'top_features': top_features,\n",
    "        'reason': \"; \".join(reasons),\n",
    "        'suggestions': \"; \".join(suggestions),\n",
    "        'genai_explanation': explanation_text\n",
    "    }\n",
    "\n",
    "    logs_df = pd.concat([logs_df, pd.DataFrame([log_entry])], ignore_index=True)\n",
    "    return log_entry\n",
    "\n",
    "# --- MAIN FUNCTION TO RUN EXPLANATIONS (ADAPTED FOR LIGHTGBM) ---\n",
    "def run_explanations_for_lgbm(model, X_test_transformed, openrouter_api_key, label_encoder, target_encoder, max_instances=5):\n",
    "    global logs_df\n",
    "    logs_df = pd.DataFrame(columns=[\n",
    "        'instance_idx', 'prediction', 'confidence', 'top_features',\n",
    "        'reason', 'suggestions', 'genai_explanation'\n",
    "    ])\n",
    "\n",
    "    print(f\"\\n🔎 Explaining top {max_instances} instances with SHAP + DeepSeek for LightGBM...\")\n",
    "\n",
    "    for idx in range(min(max_instances, len(X_test_transformed))):\n",
    "        log_entry = explain_lgbm_prediction(\n",
    "            idx, model, X_test_transformed, openrouter_api_key, label_encoder, target_encoder\n",
    "        )\n",
    "        print(f\"\\n🧾 Instance {idx} explanation:\")\n",
    "        print(log_entry)\n",
    "    print(\"\\n✅ Completed explanation batch.\")\n",
    "    print(\"\\n📋 Explanation Logs (Top 5):\")\n",
    "    print(logs_df.head())\n",
    "\n",
    "# --------------------------------------------\n",
    "# ✅ CALL FUNCTION TO GENERATE OUTPUT\n",
    "# --------------------------------------------\n",
    "# Assuming these variables are already defined from your main script:\n",
    "# lgbm (your trained LightGBM model)\n",
    "# X_test_transformed (your preprocessed and feature-selected test data)\n",
    "# openrouter_api_key (your API key)\n",
    "# label_encoder (your fitted LabelEncoder for y)\n",
    "# target_encoder (your fitted OrdinalEncoder for y)\n",
    "\n",
    "run_explanations_for_lgbm(\n",
    "    model=lgbm,\n",
    "    X_test=X_test,\n",
    "    openrouter_api_key=openrouter_api_key,\n",
    "    label_encoder=label_encoder,\n",
    "    target_encoder=target_encoder,\n",
    "    max_instances=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00331a52-1d84-40e4-8f30-8ccd4162e23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
